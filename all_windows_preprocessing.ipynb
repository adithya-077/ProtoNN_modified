{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c42e4749",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20440\\4139885538.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sb\n",
    "import os\n",
    "import joblib\n",
    "import gc\n",
    "import warnings\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from joblib import parallel_backend\n",
    "import dill\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# sb.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f5e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "    time_1=pd.read_csv(f\"./test/time_{i}.csv\")\n",
    "    freq_1=pd.read_csv(f\"./test/freq_{i}.csv\")\n",
    "\n",
    "    combined_1 = pd.concat([time_1, freq_1], axis=1)\n",
    "    combined_1=combined_1[combined_1['0']!=2]\n",
    "    combined_1.dropna(inplace=True)\n",
    "    combined_1\n",
    "\n",
    "    X = combined_1.drop('0', axis=1)\n",
    "    y = combined_1['0']\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X, y = smote.fit_resample(X, y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    X_new = combined_1.drop('0', axis=1)\n",
    "\n",
    "    data = np.column_stack((y, X))\n",
    "    columns = ['0'] + list(X_new.columns)\n",
    "    new_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    data_array = new_df.to_numpy()\n",
    "    npy_file = f\"./experiments/ttest_data_w{i}.npy\"\n",
    "    np.save(npy_file, data_array)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    time_1=pd.read_csv(f\"./train/time_{i}.csv\")\n",
    "    freq_1=pd.read_csv(f\"./train/freq_{i}.csv\")\n",
    "\n",
    "    combined_1 = pd.concat([time_1, freq_1], axis=1)\n",
    "    combined_1=combined_1[combined_1['0']!=2]\n",
    "    combined_1.dropna(inplace=True)\n",
    "    combined_1\n",
    "\n",
    "    X = combined_1.drop('0', axis=1)\n",
    "    y = combined_1['0']\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X, y = smote.fit_resample(X, y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    X_new = combined_1.drop('0', axis=1)\n",
    "\n",
    "    data = np.column_stack((y, X))\n",
    "    columns = ['0'] + list(X_new.columns)\n",
    "    new_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    data_array = new_df.to_numpy()\n",
    "    npy_file = f\"./experiments/ttrain_data_w{i}.npy\"\n",
    "    np.save(npy_file, data_array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e2ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
