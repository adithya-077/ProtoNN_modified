{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonsai in Tensorflow\n",
    "\n",
    "This is a simple notebook that illustrates the usage of Tensorflow implementation of Bonsai. We are using the USPS dataset. Please refer to `fetch_usps.py` and run it for downloading and cleaning up the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T12:06:06.056404Z",
     "start_time": "2018-08-15T12:06:05.112969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT license.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#Provide the GPU number to be used\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] =''\n",
    "\n",
    "#Bonsai imports\n",
    "from edgeml_tf.trainer.bonsaiTrainer import BonsaiTrainer\n",
    "from edgeml_tf.graph.bonsai import Bonsai\n",
    "\n",
    "# Fixing seeds for reproducibility\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sys.path.append(r\"E:\\programming\\practice\\research\\EdgeML\\examples\\tf\\Bonsai\")\n",
    "import helpermethods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USPS Data\n",
    "\n",
    "It is assumed that the USPS data has already been downloaded and set up with the help of [fetch_usps.py](fetch_usps.py) and is present in the `./usps10` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T12:06:06.104645Z",
     "start_time": "2018-08-15T12:06:06.058368Z"
    }
   },
   "outputs": [],
   "source": [
    "#Loading and Pre-processing dataset for Bonsai\n",
    "dataDir = r\"E:\\programming\\practice\\research\\bonsai\\experiments\"\n",
    "(dataDimension, numClasses, Xtrain, Ytrain, Xtest, Ytest, mean, std) = helpermethods.preProcessData(dataDir, isRegression=False)\n",
    "print(\"Feature Dimension: \", dataDimension)\n",
    "print(\"Num classes: \", numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters\n",
    "\n",
    "Note that Bonsai is designed for low-memory setting and the best results are obtained when operating in that setting. Use the sparsity, projection dimension and tree depth to vary the model size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T12:06:06.123318Z",
     "start_time": "2018-08-15T12:06:06.106847Z"
    }
   },
   "outputs": [],
   "source": [
    "sigma = 1.0 #Sigmoid parameter for tanh\n",
    "depth = 3 #Depth of Bonsai Tree\n",
    "projectionDimension = 28 #Lower Dimensional space for Bonsai to work on\n",
    "\n",
    "#Regularizers for Bonsai Parameters\n",
    "regZ = 0.0001\n",
    "regW = 0.001\n",
    "regV = 0.001\n",
    "regT = 0.001\n",
    "\n",
    "totalEpochs = 10\n",
    "\n",
    "learningRate = 0.01\n",
    "\n",
    "outFile = None\n",
    "\n",
    "#Sparsity for Bonsai Parameters. x => 100*x % are non-zeros\n",
    "sparZ = 0.2\n",
    "sparW = 0.3\n",
    "sparV = 0.3\n",
    "sparT = 0.62\n",
    "\n",
    "batchSize = np.maximum(100, int(np.ceil(np.sqrt(Ytrain.shape[0]))))\n",
    "\n",
    "useMCHLoss = False #only for Multiclass cases True: Multiclass-Hing Loss, False: Cross Entropy. \n",
    "\n",
    "#Bonsai uses one classier for Binary, thus this condition\n",
    "if numClasses == 2:\n",
    "    numClasses = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders for Data feeding during training and infernece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T12:06:06.220274Z",
     "start_time": "2018-08-15T12:06:06.125219Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float32\", [None, dataDimension])\n",
    "Y = tf.placeholder(\"float32\", [None, numClasses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a directory for current model in the datadirectory using timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T12:06:06.264985Z",
     "start_time": "2018-08-15T12:06:06.222170Z"
    }
   },
   "outputs": [],
   "source": [
    "currDir = helpermethods.createTimeStampDir(dataDir)\n",
    "helpermethods.dumpCommand(sys.argv, currDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, dataDimension], name='X')\n",
    "Y = tf.placeholder(tf.float32, [None, numClasses], name='Y')\n",
    "def objective(trial,x_train, x_test, y_train, y_test):\n",
    "    # Inside the optimization function, you use the 'trial' object to suggest hyperparameters\n",
    "    REG_W = trial.suggest_float('REG_W', 2e-6, 5e-6)\n",
    "    REG_T = trial.suggest_float('REG_W', 2e-6, 5e-6)\n",
    "    regV = trial.suggest_float('regV', 2e-5, 5e-5)\n",
    "    regZ = trial.suggest_float('regZ', 2e-5, 5e-5)\n",
    "    sparW = trial.suggest_float('sparW', 0.5, 1.0)\n",
    "    sparB = trial.suggest_float('sparB', 0.5, 1.0)\n",
    "    sparV = trial.suggest_float('sparV', 0.5, 1.0)\n",
    "    sparZ = trial.suggest_float('sparZ', 0.5, 1.0)\n",
    "    depth = trial.suggest_int('depth', 1, 10)\n",
    "        \n",
    "    LEARNING_RATE = trial.suggest_float('LEARNING_RATE', 1e-4, 1e-3)\n",
    "    NUM_EPOCHS = trial.suggest_int('NUM_EPOCHS', 400, 600)\n",
    "\n",
    "    # Set the suggested hyperparameters in the trainer\n",
    "    bonsaiObj = Bonsai(numClasses, dataDimension, projectionDimension, depth, sigma)\n",
    "    \n",
    "    \n",
    "    trainer = BonsaiTrainer(bonsaiObj, REG_W, REG_T, regV, regZ, sparW, sparB, sparV, sparZ,\n",
    "                              LEARNING_RATE, X, Y, useMCHLoss, outFile)\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    trainer.train(batchSize, NUM_EPOCHS, sess,x_train, x_test, y_train, y_test, dataDir, currDir)\n",
    "    pred = bonsaiTrainer.pred1\n",
    "    f_pred=[]\n",
    "    for i in pred:\n",
    "        if i == 0:\n",
    "            f_pred.append(1)\n",
    "        else:\n",
    "            f_pred.append(0)\n",
    "    sensitivity = confusion_matrix(Ytest,f_pred)[1][1]/(confusion_matrix(Ytest,f_pred)[1][1] + confusion_matrix(Ytest,f_pred)[1][0])\n",
    "    specificity = confusion_matrix(Ytest,f_pred)[0][0]/(confusion_matrix(Ytest,f_pred)[0][0] + confusion_matrix(Ytest,f_pred)[0][1])\n",
    "    mcc = matthews_corrcoef(y_test, f_pred)\n",
    "    return mcc + sensitivity + specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_fun = partial(objective,x_train=Xtrain, x_test=Xtest, y_train=Ytrain, y_test=Ytest)\n",
    "study.optimize(op_fun,n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonsai Graph Object\n",
    "\n",
    "Instantiating the Bonsai Graph which will be used for training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T12:06:06.341168Z",
     "start_time": "2018-08-15T12:06:06.266877Z"
    }
   },
   "outputs": [],
   "source": [
    "bonsaiObj = Bonsai(numClasses, dataDimension, projectionDimension, depth, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonsai Trainer Object\n",
    "\n",
    "Instantiating the Bonsai Trainer which will be used for 3 phase training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T12:06:07.973584Z",
     "start_time": "2018-08-15T12:06:06.342945Z"
    }
   },
   "outputs": [],
   "source": [
    "bonsaiTrainer = BonsaiTrainer(bonsaiObj, regW, regT, regV, regZ, sparW, sparT, sparV, sparZ,\n",
    "                              learningRate, X, Y, useMCHLoss, outFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session declaration and variable initialization. \n",
    "Interactive Session doesn't clog the entire GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T12:06:15.577425Z",
     "start_time": "2018-08-15T12:06:07.976090Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonsai Training Routine\n",
    "\n",
    "The method to to run the 3 phase training, followed by giving out the best early stopping model, accuracy along with saving of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T12:07:02.500241Z",
     "start_time": "2018-08-15T12:06:15.579618Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bonsaiTrainer.train(batchSize, totalEpochs, sess,\n",
    "                    Xtrain, Xtest, Ytrain, Ytest, dataDir, currDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bonsaiTrainer.pred1\n",
    "y_pred=[]\n",
    "for i in pred:\n",
    "    if i == 0:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bonsaiTrainer.pred1\n",
    "f_pred=[]\n",
    "for i in pred:\n",
    "    if i == 0:\n",
    "        f_pred.append(1)\n",
    "    else:\n",
    "        f_pred.append(0)\n",
    "sensitivity = confusion_matrix(Ytest,f_pred)[1][1]/(confusion_matrix(Ytest,f_pred)[1][1] + confusion_matrix(Ytest,f_pred)[1][0])\n",
    "specificity = confusion_matrix(Ytest,f_pred)[0][0]/(confusion_matrix(Ytest,f_pred)[0][0] + confusion_matrix(Ytest,f_pred)[0][1])\n",
    "print(f\"sensitivity: {sensitivity} specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print (confusion_matrix(Ytest,y_pred))\n",
    "print (classification_report(Ytest,y_pred,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonsaiTrainer.sigmaI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
